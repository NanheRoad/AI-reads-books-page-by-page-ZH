from ,athlib import Path
from typing import Dict, Any, Optional
from pydantic import BaseModel
import json
from openai import OpenAI
import fitz  # PyMuPDF
from termcolor import colored
from datetime import datetime
import shutil

# source for the infinite descent book: https://infinitedescent.xyz/dl/infdesc.pdf

""" 
ä½¿ç”¨å‰éœ€è®¾ç½®ç¯å¢ƒå˜é‡
1.ä¸´æ—¶è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆä»…å¯¹å½“å‰ç»ˆç«¯ä¼šè¯æœ‰æ•ˆï¼‰ï¼š
export OPENAI_API_KEY=your_api_key_here
2.æ°¸ä¹…è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¯¹æ‰€æœ‰ç»ˆç«¯ä¼šè¯æœ‰æ•ˆï¼‰ï¼š
åœ¨ ~/.bashrc æˆ– ~/.zshrc æ–‡ä»¶ä¸­æ·»åŠ ä»¥ä¸‹è¡Œï¼š
export OPENAI_API_KEY=your_api_key_here
ç„¶åè¿è¡Œä»¥ä¸‹å‘½ä»¤ä½¿æ›´æ”¹ç”Ÿæ•ˆï¼š
source ~/.bashrc  # æˆ– source ~/.zshrc
3.åœ¨ä»£ç ä¸­ä¼ é€’ API å¯†é’¥ï¼ˆä¸æ¨èï¼‰
å¦‚æœä½ é€‰æ‹©åœ¨ä»£ç ä¸­ä¼ é€’ API å¯†é’¥ï¼Œè¯·ç¡®ä¿å°†å…¶å­˜å‚¨åœ¨å®‰å…¨çš„ä½ç½®ï¼Œå¹¶ä¸”ä¸è¦å°†å…¶æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿä¸­ã€‚
client = OpenAI(api_key="your_api_key_here") 
"""


# é…ç½®å¸¸é‡
PDF_NAME = "meditations.pdf"
BASE_DIR = Path("book_analysis")
PDF_DIR = BASE_DIR / "pdfs"
KNOWLEDGE_DIR = BASE_DIR / "knowledge_bases"
SUMMARIES_DIR = BASE_DIR / "summaries"
PDF_PATH = PDF_DIR / PDF_NAME
OUTPUT_PATH = KNOWLEDGE_DIR / f"{PDF_NAME.replace('.pdf', '_knowledge.json')}"
ANALYSIS_INTERVAL = 20  # è®¾ç½®ä¸ºNoneä»¥è·³è¿‡é—´éš”åˆ†æï¼Œæˆ–è®¾ç½®ä¸ºæ•°å­—ï¼ˆä¾‹å¦‚ï¼Œ10ï¼‰ä»¥æ¯Né¡µç”Ÿæˆåˆ†æ
MODEL = "gpt-4o-mini"
ANALYSIS_MODEL = "o1-mini"
TEST_PAGES = 60  # è®¾ç½®ä¸ºNoneä»¥å¤„ç†æ•´æœ¬ä¹¦


class PageContent(BaseModel):
    has_content: bool
    knowledge: list[str]


def load_or_create_knowledge_base() -> Dict[str, Any]:
    if Path(OUTPUT_PATH).exists():
        with open(OUTPUT_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_knowledge_base(knowledge_base: list[str]):
    output_path = KNOWLEDGE_DIR / f"{PDF_NAME.replace('.pdf', '')}_knowledge.json"
    print(colored(f"ğŸ’¾ ä¿å­˜çŸ¥è¯†åº“ï¼ˆ{len(knowledge_base)} é¡¹ï¼‰...", "blue"))
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump({"knowledge": knowledge_base}, f, indent=2)

def process_page(client: OpenAI, page_text: str, current_knowledge: list[str], page_num: int) -> list[str]:
    print(colored(f"\nğŸ“– å¤„ç†ç¬¬ {page_num + 1} é¡µ...", "yellow"))
    
    completion = client.beta.chat.completions.parse(
        model=MODEL,
        messages=[
            {"role": "system", "content": """åˆ†ææ­¤é¡µé¢ï¼Œå¦‚åŒä½ åœ¨å­¦ä¹ ä¸€æœ¬ä¹¦ã€‚

            è·³è¿‡åŒ…å«ä»¥ä¸‹å†…å®¹çš„é¡µé¢ï¼š
            - ç›®å½•
            - ç« èŠ‚åˆ—è¡¨
            - ç´¢å¼•é¡µé¢
            - ç©ºç™½é¡µé¢
            - ç‰ˆæƒä¿¡æ¯
            - å‡ºç‰ˆè¯¦æƒ…
            - å‚è€ƒæ–‡çŒ®æˆ–ä¹¦ç›®
            - è‡´è°¢
            
            æå–çŸ¥è¯†å¦‚æœé¡µé¢åŒ…å«ä»¥ä¸‹å†…å®¹ï¼š
            - è§£é‡Šé‡è¦æ¦‚å¿µçš„å‰è¨€å†…å®¹
            - å®é™…æ•™è‚²å†…å®¹
            - å…³é”®å®šä¹‰å’Œæ¦‚å¿µ
            - é‡è¦è®ºç‚¹æˆ–ç†è®º
            - ç¤ºä¾‹å’Œæ¡ˆä¾‹ç ”ç©¶
            - æ˜¾è‘—å‘ç°æˆ–ç»“è®º
            - æ–¹æ³•è®ºæˆ–æ¡†æ¶
            - æ‰¹åˆ¤æ€§åˆ†ææˆ–è§£é‡Š
            
            å¯¹äºæœ‰æ•ˆå†…å®¹ï¼š
            - å°† has_content è®¾ç½®ä¸º true
            - æå–è¯¦ç»†çš„ã€å¯å­¦ä¹ çš„çŸ¥è¯†ç‚¹
            - åŒ…æ‹¬é‡è¦å¼•ç”¨æˆ–å…³é”®é™ˆè¿°
            - æ•è·ç¤ºä¾‹åŠå…¶ä¸Šä¸‹æ–‡
            - ä¿ç•™æŠ€æœ¯æœ¯è¯­å’Œå®šä¹‰
            
            å¯¹äºè¦è·³è¿‡çš„é¡µé¢ï¼š
            - å°† has_content è®¾ç½®ä¸º false
            - è¿”å›ç©ºçŸ¥è¯†åˆ—è¡¨"""},
            {"role": "user", "content": f"é¡µé¢æ–‡æœ¬: {page_text}"}
        ],
        response_format=PageContent
    )
    
    result = completion.choices[0].message.parsed
    if result.has_content:
        print(colored(f"âœ… æ‰¾åˆ° {len(result.knowledge)} ä¸ªæ–°çŸ¥è¯†ç‚¹", "green"))
    else:
        print(colored("â­ï¸  è·³è¿‡é¡µé¢ï¼ˆæ— ç›¸å…³å†…å®¹ï¼‰", "yellow"))
    
    updated_knowledge = current_knowledge + (result.knowledge if result.has_content else [])
    
    # æ›´æ–°å•ä¸ªçŸ¥è¯†åº“æ–‡ä»¶
    save_knowledge_base(updated_knowledge)
    
    return updated_knowledge

def load_existing_knowledge() -> list[str]:
    knowledge_file = KNOWLEDGE_DIR / f"{PDF_NAME.replace('.pdf', '')}_knowledge.json"
    if knowledge_file.exists():
        print(colored("ğŸ“š åŠ è½½ç°æœ‰çŸ¥è¯†åº“...", "cyan"))
        with open(knowledge_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            print(colored(f"âœ… åŠ è½½äº† {len(data['knowledge'])} ä¸ªç°æœ‰çŸ¥è¯†ç‚¹", "green"))
            return data['knowledge']
    print(colored("ğŸ†• ä»ç©ºç™½çŸ¥è¯†åº“å¼€å§‹", "cyan"))
    return []

def analyze_knowledge_base(client: OpenAI, knowledge_base: list[str]) -> str:
    if not knowledge_base:
        print(colored("\nâš ï¸  è·³è¿‡åˆ†æï¼šæœªæ”¶é›†åˆ°çŸ¥è¯†ç‚¹", "yellow"))
        return ""
        
    print(colored("\nğŸ¤” ç”Ÿæˆæœ€ç»ˆä¹¦ç±åˆ†æ...", "cyan"))
    completion = client.chat.completions.create(
        model=MODEL,
        messages=[
            {"role": "system", "content": """åˆ›å»ºæ‰€æä¾›å†…å®¹çš„ç»¼åˆæ‘˜è¦ï¼Œæ ¼å¼ç®€æ´ä½†è¯¦ç»†ï¼Œä½¿ç”¨ä»£ç æ ¼å¼ã€‚
           
            ä½¿ç”¨ä»£ç æ ¼å¼ï¼š
            - ## ç”¨äºä¸»æ ‡é¢˜
            - ### ç”¨äºå­æ ‡é¢˜
            - é¡¹ç›®ç¬¦å·ç”¨äºåˆ—è¡¨
            - `ä»£ç å—` ç”¨äºä»»ä½•ä»£ç æˆ–å…¬å¼
            - **ç²—ä½“** ç”¨äºå¼ºè°ƒ
            - *æ–œä½“* ç”¨äºæœ¯è¯­
            - > å—å¼•ç”¨ç”¨äºé‡è¦ç¬”è®°
            
            ä»…è¿”å›ä»£ç æ‘˜è¦ï¼Œä¸è¦åœ¨å‰åæ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹ï¼Œå¦‚â€œä»¥ä¸‹æ˜¯æ‘˜è¦â€ç­‰"""},
            {"role": "user", "content": f"åˆ†ææ­¤å†…å®¹ï¼š\n" + "\n".join(knowledge_base)}
        ]
    )
    
    print(colored("âœ¨ åˆ†æç”ŸæˆæˆåŠŸï¼", "green"))
    return completion.choices[0].message.content

def setup_directories():
    # æ¸…é™¤æ‰€æœ‰å…ˆå‰ç”Ÿæˆçš„æ–‡ä»¶
    for directory in [KNOWLEDGE_DIR, SUMMARIES_DIR]:
        if directory.exists():
            for file in directory.glob("*"):
                file.unlink()  # åˆ é™¤è¿™äº›ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    
    # åˆ›å»ºæ‰€æœ‰å¿…è¦çš„ç›®å½•
    for directory in [PDF_DIR, KNOWLEDGE_DIR, SUMMARIES_DIR]:
        directory.mkdir(parents=True, exist_ok=True)
    
    # ç¡®ä¿PDFä½äºæ­£ç¡®ä½ç½®
    if not PDF_PATH.exists():
        source_pdf = Path(PDF_NAME)
        if source_pdf.exists():
            # å¤åˆ¶PDFè€Œä¸æ˜¯ç§»åŠ¨å®ƒ
            shutil.copy2(source_pdf, PDF_PATH)
            print(colored(f"ğŸ“„ å°†PDFå¤åˆ¶åˆ°åˆ†æç›®å½•ï¼š{PDF_PATH}", "green"))
        else:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°PDFæ–‡ä»¶ {PDF_NAME}")

def save_summary(summary: str, is_final: bool = False):
    if not summary:
        print(colored("â­ï¸  è·³è¿‡æ‘˜è¦ä¿å­˜ï¼šæ— å†…å®¹å¯ä¿å­˜", "yellow"))
        return
        
    # ä½¿ç”¨é€‚å½“çš„å‘½ååˆ›å»ºä»£ç æ–‡ä»¶
    if is_final:
        existing_summaries = list(SUMMARIES_DIR.glob(f"{PDF_NAME.replace('.pdf', '')}_final_*.md"))
        next_number = len(existing_summaries) + 1
        summary_path = SUMMARIES_DIR / f"{PDF_NAME.replace('.pdf', '')}_final_{next_number:03d}.md"
    else:
        existing_summaries = list(SUMMARIES_DIR.glob(f"{PDF_NAME.replace('.pdf', '')}_interval_*.md"))
        next_number = len(existing_summaries) + 1
        summary_path = SUMMARIES_DIR / f"{PDF_NAME.replace('.pdf', '')}_interval_{next_number:03d}.md"
    
    # åˆ›å»ºå¸¦æœ‰å…ƒæ•°æ®çš„ä»£ç å†…å®¹
    code_content = f"""# ä¹¦ç±åˆ†æ: {PDF_NAME}
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

{summary}

---
*ä½¿ç”¨AIä¹¦ç±åˆ†æå·¥å…·ç”Ÿæˆçš„åˆ†æ*
"""
    
    print(colored(f"\nğŸ“ ä¿å­˜ {'æœ€ç»ˆ' if is_final else 'é—´éš”'}åˆ†æåˆ°ä»£ç ...", "cyan"))
    with open(summary_path, 'w', encoding='utf-8') as f:  # æ·»åŠ äº†encoding='utf-8'
        f.write(code_content)
    print(colored(f"âœ… åˆ†æå·²ä¿å­˜åˆ°: {summary_path}", "green"))


def print_instructions():
    print(colored("""\
ğŸ“š PDFä¹¦ç±åˆ†æå·¥å…· ğŸ“š
---------------------------
1. å°†æ‚¨çš„PDFæ–‡ä»¶æ”¾ç½®åœ¨ä¸è¯¥è„šæœ¬ç›¸åŒçš„ç›®å½•ä¸­
2. æ›´æ–°PDF_NAMEå¸¸é‡ä»¥ä½¿ç”¨æ‚¨çš„PDFæ–‡ä»¶å
3. è¯¥è„šæœ¬å°†ï¼š
   - é€é¡µå¤„ç†ä¹¦ç±
   - æå–å¹¶ä¿å­˜çŸ¥è¯†ç‚¹
   - ç”Ÿæˆé—´éš”æ‘˜è¦ï¼ˆå¦‚æœå¯ç”¨ï¼‰
   - åˆ›å»ºæœ€ç»ˆçš„ç»¼åˆåˆ†æ

é…ç½®é€‰é¡¹ï¼š
- ANALYSIS_INTERVAL: è®¾ç½®ä¸ºNoneä»¥è·³è¿‡é—´éš”åˆ†æï¼Œæˆ–è®¾ç½®ä¸ºæ•°å­—ä»¥æ¯Né¡µè¿›è¡Œåˆ†æ
- TEST_PAGES: è®¾ç½®ä¸ºNoneä»¥å¤„ç†æ•´æœ¬ä¹¦ï¼Œæˆ–è®¾ç½®ä¸ºæ•°å­—ä»¥è¿›è¡Œéƒ¨åˆ†å¤„ç†

æŒ‰Enterç»§ç»­æˆ–æŒ‰Ctrl+Cé€€å‡º...
""", "cyan"))


def main():
    try:
        print_instructions()
        input()
    except KeyboardInterrupt:
        print(colored("\nâŒ ç”¨æˆ·å–æ¶ˆäº†è¿›ç¨‹", "red"))
        return

    setup_directories()
    client = OpenAI()
    
    # åŠ è½½æˆ–åˆå§‹åŒ–çŸ¥è¯†åº“
    knowledge_base = load_existing_knowledge()
    
    pdf_document = fitz.open(PDF_PATH)
    pages_to_process = TEST_PAGES if TEST_PAGES is not None else pdf_document.page_count
    
    print(colored(f"\nğŸ“š æ­£åœ¨å¤„ç† {pages_to_process} é¡µ...", "cyan"))
    for page_num in range(min(pages_to_process, pdf_document.page_count)):
        page = pdf_document[page_num]
        page_text = page.get_text()
        
        knowledge_base = process_page(client, page_text, knowledge_base, page_num)
        
        # å¦‚æœè®¾ç½®äº†ANALYSIS_INTERVALï¼Œåˆ™ç”Ÿæˆé—´éš”åˆ†æ
        if ANALYSIS_INTERVAL:
            is_interval = (page_num + 1) % ANALYSIS_INTERVAL == 0
            is_final_page = page_num + 1 == pages_to_process
            
            if is_interval and not is_final_page:
                print(colored(f"\nğŸ“Š è¿›åº¦: {page_num + 1}/{pages_to_process} é¡µå·²å¤„ç†", "cyan"))
                interval_summary = analyze_knowledge_base(client, knowledge_base)
                save_summary(interval_summary, is_final=False)
        
        # å§‹ç»ˆåœ¨æœ€åä¸€é¡µç”Ÿæˆæœ€ç»ˆåˆ†æ
        if page_num + 1 == pages_to_process:
            print(colored(f"\nğŸ“Š æœ€åä¸€é¡µ ({page_num + 1}/{pages_to_process}) å·²å¤„ç†", "cyan"))
            final_summary = analyze_knowledge_base(client, knowledge_base)
            save_summary(final_summary, is_final=True)
    
    print(colored("\nâœ¨ å¤„ç†å®Œæˆï¼ âœ¨", "green", attrs=['bold']))


if __name__ == "__main__":
    main()